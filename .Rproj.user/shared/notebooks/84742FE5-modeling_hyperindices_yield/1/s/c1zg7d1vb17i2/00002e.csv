"0","# LASSO regression with glmnet"
"0","#####################################################################################################"
"0","# import the data"
"0","drybean <- read.csv(""Bean_Othello_Jul21_M10_transparent_reflectance_hyperindices.csv"") %>% na.omit()"
"0",""
"0","# predicting YIELD"
"0","drybean.sub <- drybean %>%"
"0","  select(kgha, ends_with(""_mean"")) %>%"
"0","  na.omit()"
"0",""
"0",""
"0",""
"0",""
"0","# # where are the coefficients NA. We will remove these from the model"
"0","# drybean.reduced <- drybean.sub %>% select(-c(X9_mean, X18_mean, X19_mean, X27_mean,"
"0","#                                             X28_mean,  X29_mean, X36_mean,  X37_mean, X38_mean,"
"0","#                                             X39_mean, X45_mean,  X46_mean, X47_mean,  X48_mean,"
"0","#                                             X49_mean,  X54_mean, X55_mean,  X56_mean, X57_mean,"
"0","#                                             X58_mean, X59_mean,  X63_mean, X64_mean,  X65_mean, "
"0","#                                             X66_mean,  X67_mean, X68_mean,  X69_mean, X72_mean, "
"0","#                                             X73_mean, X74_mean,  X75_mean, X76_mean,  X77_mean,"
"0","#                                             X78_mean,  X79_mean, X81_mean, X82_mean,  X83_mean,"
"0","#                                             X84_mean, X85_mean, X86_mean,  X87_mean, X88_mean,"
"0","#                                             X89_mean))"
"0",""
"0","# # Split the data into training and test set"
"0","set.seed(123)"
"0",""
"0","training.samples <- drybean.sub$kgha %>%"
"0","  createDataPartition(p = 0.8, list = FALSE)"
"0",""
"0","train.data  <- as.matrix(drybean.sub[training.samples, ])"
"0","train.x <- train.data[,2:ncol(train.data)]"
"0","train.y <- train.data[,1]"
"0",""
"0","test.data <- as.matrix(drybean.sub[-training.samples, ])"
"0","test.x <- test.data[,2:ncol(test.data)]"
"0","test.y <- test.data[,1]"
"0",""
"0",""
"0","# LASSO regression model, Least Absolutel Shrinkage and Selection Operator"
"0","# in the glmnet library"
"0","lambda_seq <- 10^seq(2, -2, by = -.1)"
"0",""
"0",""
"0","# cvfit <- cv.glmnet(, alpha = 1, lambda = lambda_seq,"
"0","#                        nfolds = 10)"
"0","cvfit <- cv.glmnet(train.x, train.y, type.measure = ""mse"", nfolds = 20)"
"0",""
"0",""
"0","best_lam <- cvfit$lambda.min"
"0","best_lam"
"1","[1]"
"1"," 25.8951"
"1","
"
"0","# build the model with the best lambda value"
"0","lasso_best <- glmnet(train.x, train.y, alpha = 1, lambda = best_lam)"
"0",""
"0","# make predictions"
"0","pred <- predict(lasso_best, s = best_lam, newx = test.x)"
"0","final <- cbind(test.y, pred)"
"0",""
"0","# check the first few"
"0","head(final)"
"1","  "
"1"," test.y"
"1","        1"
"1","
5 "
"1"," 3269.2"
"1"," 4154.756"
"1","
8 "
"1"," 4838.5"
"1"," 4479.109"
"1","
15"
"1"," 4160.1"
"1"," 3463.547"
"1","
33"
"1"," 3679.5"
"1"," 3823.251"
"1","
41"
"1"," 4272.9"
"1"," 4305.753"
"1","
44"
"1"," 4019.4"
"1"," 4290.361"
"1","
"
"0","# # compute R MSE"
"0","RMSE <- RMSE(pred, test.y)"
"0",""
"0","# "
"0","# # compute R-square"
"0","R2 <- R2(pred, test.y)"
"0",""
"0",""
"0",""
"0",""
"0","# return results"
"0","print(paste(""RMSE = "", RMSE))"
"1","[1]"
"1"," ""RMSE =  515.764244374927"""
"1","
"
"0","print(paste(""R-squared value is:"", round(R2,4)))"
"1","[1]"
"1"," ""R-squared value is: 0.2198"""
"1","
"
"0","R2label <- paste(""r^2="", round(R2,4))"
"0",""
"0",""
"0","# combine the real and predicted values"
"0","glm_yield <- tibble(test.y, pred)"
"0","names(glm_yield) <- c(""real_kgha"", ""pred_kgha"")"
"0",""
"0","# make a plot of predictions"
"0","yield_plot <- glm_yield %>% "
"0","  ggplot(aes(x=real_kgha, y=pred_kgha)) + "
"0","  geom_point() +"
"0","  theme_bw() +"
"0","  ggtitle(""GLM lasso: real kgha vs predicted kgha"") +"
"0","  ylab(""predicted yield (kgha)"") +"
"0","  xlab(""yield (kgha)"") +"
"0","  annotate(geom=""text"", x=5000, y=5000,size=6, color = ""red"", label=R2label)"
"0",""
"0",""
"0","yield_plot"
